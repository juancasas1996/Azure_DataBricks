{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce53d4c2-1de2-40c5-bf47-5f10e4032747",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Exercise: Select Optimal Model by Tuning Hyperparameters\n",
    "\n",
    "Use grid search and cross-validation to tune the hyperparameters from a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3b7d5c5-efbb-4d51-8499-43ef215748fd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Run the following cell to set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da77a282-530b-46d3-a5ce-3ee82a68a1e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./Includes/Classroom-Setup\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b46d737-9f3c-40f4-9aeb-2ae83c444510",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 1: Import the Data\n",
    "\n",
    "Import the data and perform a train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02cd709f-3b12-4f30-a40d-8964a107671f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "cols = [\"index\",\n",
    " \"sample-code-number\",\n",
    " \"clump-thickness\",\n",
    " \"uniformity-of-cell-size\",\n",
    " \"uniformity-of-cell-shape\",\n",
    " \"marginal-adhesion\",\n",
    " \"single-epithelial-cell-size\",\n",
    " \"bare-nuclei\",\n",
    " \"bland-chromatin\",\n",
    " \"normal-nucleoli\",\n",
    " \"mitoses\",\n",
    " \"class\"]\n",
    "\n",
    "cancerDF = (spark.read  # read the data\n",
    "  .option(\"HEADER\", True)\n",
    "  .option(\"inferSchema\", True)\n",
    "  .csv(\"/mnt/training/cancer/biopsy/biopsy.csv\")\n",
    ")\n",
    "\n",
    "cancerDF = (cancerDF    # Add column names and drop nulls\n",
    "  .toDF(*cols)\n",
    "  .withColumn(\"bare-nuclei\", col(\"bare-nuclei\").isNotNull().cast(\"integer\"))\n",
    ")\n",
    "\n",
    "display(cancerDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "caddf120-2755-41d9-bbb4-15b9cb657733",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Perform a train/test split to create `trainCancerDF` and `testCancerDF`.  Put 80% of the data in `trainCancerDF` and use the seed that is set for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea05acba-013e-4e93-be50-377674b449b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "seed = 42\n",
    "trainCancerDF, testCancerDF = # FILL_IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50f8ceff-ce7a-446a-915e-1f980ce72f2d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 2: Create a Pipeline\n",
    "\n",
    "Create a pipeline `cancerPipeline` that consists of the following stages:<br>\n",
    "\n",
    "1. `indexer`: a `StringIndexer` that takes `class` as an input and outputs the column `is-malignant`\n",
    "2. `assembler`: a `VectorAssembler` that takes all of the other columns as an input and outputs  the column `features`\n",
    "3. `logr`: a `LogisticRegression` that takes `features` as the input and `is-malignant` as the output variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a817c86-62a4-481a-b018-c1c1c00fda1a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# indexer = # FILL_IN\n",
    "# assembler = # FILL_IN\n",
    "# logr = # FILL_IN\n",
    "# cancerPipeline = # FILL_IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a762002-9965-4e3e-bee8-2652d4b83356",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TEST - Run this cell to test your solution\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "\n",
    "dbTest(\"ML1-P-08-02-01\", True, type(indexer) == type(StringIndexer()))\n",
    "dbTest(\"ML1-P-08-02-02\", True, indexer.getInputCol() == 'class')\n",
    "dbTest(\"ML1-P-08-02-03\", True, indexer.getOutputCol() == 'is-malignant')\n",
    "\n",
    "dbTest(\"ML1-P-08-02-04\", True, type(assembler) == type(VectorAssembler()))\n",
    "dbTest(\"ML1-P-08-02-05\", True, assembler.getInputCols() == cols[2:-1])\n",
    "dbTest(\"ML1-P-08-02-06\", True, assembler.getOutputCol() == 'features')\n",
    "\n",
    "dbTest(\"ML1-P-08-02-07\", True, type(logr) == type(LogisticRegression()))\n",
    "dbTest(\"ML1-P-08-02-08\", True, logr.getLabelCol() == \"is-malignant\")\n",
    "dbTest(\"ML1-P-08-02-09\", True, logr.getFeaturesCol() == 'features')\n",
    "\n",
    "dbTest(\"ML1-P-08-02-10\", True, type(cancerPipeline) == type(Pipeline()))\n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5162ae6d-572d-4b4e-9c87-2a2ad71b0888",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 3: Create Grid Search Parameters\n",
    "\n",
    "Take a look at the parameters for our `LogisticRegression` object.  Use this to build the inputs to grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5cd383b9-81c0-45f1-9dc2-6577d87db1c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(logr.explainParams())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80e3cc23-220b-42bd-bcb9-808481f77e06",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Create a `ParamGridBuilder` object with two grids:<br><br>\n",
    "\n",
    "1. A regularization parameter `regParam` of `[0., .2, .8, 1.]`\n",
    "2. Test both with and without an intercept using `fitIntercept`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fefb318c-aad6-49f3-9cdf-d35c2f52eada",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "cancerParamGrid = (ParamGridBuilder()\n",
    "  # FILL_IN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b41a4b1-293e-4dae-852e-f73ee0fbbd5a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TEST - Run this cell to test your solution\n",
    "dbTest(\"ML1-P-08-03-01\", True, type(cancerParamGrid) == list)\n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3612f4c3-67a8-412e-b136-fb3404754fd7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 4: Perform 3-Fold Cross-Validation\n",
    "\n",
    "Create a `BinaryClassificationEvaluator` object and use it to perform 3-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba75ec9a-f538-4201-b17f-f7a2a75ecba4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "binaryEvaluator = BinaryClassificationEvaluator(\n",
    "  labelCol = \"is-malignant\", \n",
    "  metricName = \"areaUnderROC\"\n",
    ")\n",
    "\n",
    "cancerCV = CrossValidator(\n",
    "  estimator = # FILL_IN,              # Estimator (individual model or pipeline)\n",
    "  estimatorParamMaps = # FILL_IN,     # Grid of parameters to try (grid search)\n",
    "  evaluator= # FILL_IN,               # Evaluator\n",
    "  numFolds = # FILL_IN,               # Set k to 3\n",
    "  seed = 42                           # Seed to sure our results are the same if ran again\n",
    ")\n",
    "\n",
    "cancerCVModel = cancerCV.fit(trainCancerDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ab415fc-35ff-4047-bc21-ea8393cfc386",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TEST - Run this cell to test your solution\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "dbTest(\"ML1-P-08-04-01\", True, type(binaryEvaluator) == type(BinaryClassificationEvaluator()))\n",
    "dbTest(\"ML1-P-08-04-02\", True, type(cancerCV) == type(CrossValidator()))\n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "175d060b-bde4-4b45-b62a-674b78c396cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 5: Examine the results\n",
    "\n",
    "Take a look at the results.  Which combination of hyperparameters learned the most from the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75d0721d-6f27-4447-bb3a-1a83a0d1adbd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for params, score in zip(cancerCVModel.getEstimatorParamMaps(), cancerCVModel.avgMetrics):\n",
    "  print(\"\".join([param.name+\"\\t\"+str(params[param])+\"\\t\" for param in params]))\n",
    "  print(\"\\tScore: {}\".format(score))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "2. Exercise Model Selection",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
